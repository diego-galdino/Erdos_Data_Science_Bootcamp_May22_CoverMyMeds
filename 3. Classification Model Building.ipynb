{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654022487208,
     "user": {
      "displayName": "Diego Ribeiro de Oliveira Galdino",
      "userId": "09301364934909737437"
     },
     "user_tz": 240
    },
    "id": "8VnhUtFKnuXX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8112,
     "status": "ok",
     "timestamp": 1654022495320,
     "user": {
      "displayName": "Diego Ribeiro de Oliveira Galdino",
      "userId": "09301364934909737437"
     },
     "user_tz": 240
    },
    "id": "_Bw1Dw2ZACIL"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# data = pd.read_csv('/content/drive/MyDrive/Erdos Bootcamp May 2022/Project/CoverMyMeds Project/pharmacy_tx.csv')\n",
    "data = pd.read_csv('C:/Users/diego/Google Drive/Erdos Bootcamp May 2022/Project/CoverMyMeds Project/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NaN with NA. They are all located in PCN and GROUP columns. Keep NA as a different category.\n",
    "data = data.fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set type of all features to save memory\n",
    "data = data.astype({'tx_date':'datetime64[ns]', \n",
    "                    'month_name': 'category', \n",
    "                    'day_name': 'category', \n",
    "                    'pharmacy': 'category', \n",
    "                    'bin_pcn_group': 'category', \n",
    "                    'bin': 'category', \n",
    "                    'pcn': 'category', \n",
    "                    'group': 'category',\n",
    "                    'drug_brand': 'category',\n",
    "                    'drug_name': 'category',\n",
    "                    'diag_letter': 'category',\n",
    "                    'diag_num1': 'category',\n",
    "                    'diag_num2': 'category',\n",
    "                    'patient_pay': 'float32'\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['patient_pay'])\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlIW3ZvHz_mJ"
   },
   "source": [
    "# Classification Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1654021322949,
     "user": {
      "displayName": "Diego Ribeiro de Oliveira Galdino",
      "userId": "09301364934909737437"
     },
     "user_tz": 240
    },
    "id": "Pogb9saW0C3h",
    "outputId": "3d66435a-bc54-4e3a-92e5-b029f77c6e64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_feature_selection(data, dep_feature, test_size=0.2, random_state=614):\n",
    "    # Separate X and y from the dataframe that has all columns\n",
    "    X = data.drop(columns=[dep_feature])\n",
    "    y = data[dep_feature]\n",
    "    \n",
    "    # Split train and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_mean_scores(model, X, y, sampling, curves):\n",
    "\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "#     X_train = X_train.reset_index(drop=True)\n",
    "#     X_val = X_val.reset_index(drop=True)\n",
    "#     y_train = y_train.reset_index(drop=True)\n",
    "#     y_val = y_val.reset_index(drop=True)\n",
    "\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    metrics = {'neg_log_loss':[], 'accuracy':[], 'precision':[], 'recall':[], 'f1':[], 'roc_auc':[], 'ap':[]}\n",
    "    estimators = []\n",
    "    \n",
    "    X_parts = np.array_split(X, 5)\n",
    "    for i in range(5):\n",
    "        X_val_temp = X.loc[list(X_parts[i].index)]\n",
    "        y_val_temp = y.loc[list(X_parts[i].index)]\n",
    "        \n",
    "        for j in range(5):\n",
    "            if j == 0:\n",
    "                X_train_temp = pd.DataFrame()\n",
    "                y_train_temp = pd.Series()\n",
    "            if j != i:\n",
    "                X_train_temp = X_train_temp.append(X.loc[list(X_parts[j].index)])\n",
    "                y_train_temp = y_train_temp.append(y.loc[list(X_parts[j].index)])\n",
    "        \n",
    "        if sampling == 'over':\n",
    "            X_train_temp, y_train_temp = over_sampling(X_train_temp, y_train_temp)\n",
    "        elif sampling == 'under':\n",
    "            X_train_temp, y_train_temp = under_sampling(X_train_temp, y_train_temp)\n",
    "        \n",
    "        model.fit(X_train_temp, y_train_temp)\n",
    "        y_pred_val = model.predict(X_val_temp)\n",
    "        y_prob_val = model.predict_proba(X_val_temp)[:,-1]\n",
    "        \n",
    "        neg_log_loss = -1*log_loss(y_val_temp, y_pred_val)\n",
    "        accuracy = accuracy_score(y_val_temp, y_pred_val)\n",
    "        precision = precision_score(y_val_temp, y_pred_val)\n",
    "        recall = recall_score(y_val_temp, y_pred_val)\n",
    "        f1 = f1_score(y_val_temp, y_pred_val)\n",
    "        roc_auc = roc_auc_score(y_val_temp, y_prob_val)\n",
    "        ap = average_precision_score(y_val_temp, y_prob_val)\n",
    "        \n",
    "        metrics['neg_log_loss'].append(neg_log_loss)\n",
    "        metrics['accuracy'].append(accuracy)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "        metrics['f1'].append(f1)\n",
    "        metrics['roc_auc'].append(roc_auc)\n",
    "        metrics['ap'].append(ap)\n",
    "        \n",
    "        estimators.append(model)\n",
    "        \n",
    "        if curves:\n",
    "            roc_curve_plot(model, X_val_temp, y_val_temp)\n",
    "            prec_recall_curve_plot(model, X_val_temp, y_val_temp)\n",
    "        \n",
    "    # Calculate the positive mean of the metrics\n",
    "    metrics_mean = list()\n",
    "    for metric in metrics.keys():\n",
    "        if list(metrics.keys()).index(metric) == 0:\n",
    "            best_estimator = estimators[np.nanargmax(np.array(metrics[metric]))]\n",
    "        metrics_mean.append(np.nanmean(np.array(metrics[metric])))\n",
    "    \n",
    "    # Save the best estimator\n",
    "    save_path = ['./models/', str(best_estimator).split('(')[0], '_', str(metrics_mean[0])]\n",
    "    dump(best_estimator, ''.join(save_path + ['.joblib']))\n",
    "    \n",
    "    return best_estimator, metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(x, y, title, xlabel, ylabel, show=True):\n",
    "    plt.figure(figsize=(14,7))\n",
    "    sns.scatterplot(x=x, y=y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel, fontsize=12)\n",
    "    plt.ylabel(ylabel, fontsize=12)\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(model, pred, resid):\n",
    "    title = 'Residual plot of {}'.format(model)\n",
    "    xlabel = 'y_predicted'\n",
    "    ylabel = 'y_observed - y_predicted'\n",
    "    scatterplot(pred, resid, title, xlabel, ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_obs(y_test, model, pred):\n",
    "    title = 'Predicted vs Observed plot of {}'.format(model)\n",
    "    xlabel = 'observed'\n",
    "    ylabel = 'predicted'\n",
    "    scatterplot(y_test, pred, title, xlabel, ylabel, show=False)\n",
    "    plt.plot(y_test, y_test, 'b-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_features_plot(model, X):\n",
    "    # Barplot of the shap values if available\n",
    "    try:\n",
    "        explainer = shap.explainers.Tree(model)\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        shap.plots.bar(shap.Explanation(shap_values))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model):\n",
    "    # Print feature importance if available\n",
    "    try:\n",
    "        feature_importance = ['{}: {}'.format(f,i) for f,i in zip(model.feature_name_, model.feature_importances_)]\n",
    "        print('Feature Importance: ' + ', '.join(feature_importance))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(X, y, metrics, model, sampling, curves):\n",
    "    # Call cross-validation and take the total processing time of it\n",
    "    t0 = time.time()\n",
    "    best_estimator, metrics_mean = cross_validation_mean_scores(model, X, y, sampling, curves)\n",
    "    t1 = time.time() - t0\n",
    "    \n",
    "    # Print a summary of the metrics for the best fitted estimator\n",
    "    print('-> Model: {}'.format(best_estimator))\n",
    "    model_summary = ['Train {}: {:.4f}'.format(m.replace('neg_',''),s) for m,s in zip(metrics, metrics_mean)] + ['Proc Time: {:.2f}'.format(t1)]\n",
    "    print(', '.join(model_summary))\n",
    "\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(model, X, y):\n",
    "    # Predict y\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:,-1]\n",
    "    \n",
    "    # Calculate scores\n",
    "    neg_log_loss = -1*log_loss(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    roc_auc = roc_auc_score(y, y_prob)\n",
    "    ap = average_precision_score(y, y_prob)\n",
    "    \n",
    "    # Print MSE and MAPE\n",
    "    print('Test NegLogLoss {:.4f}, Test Accuracy {:.4f}, Test Precision {:.4f}, Test Recall {:.4f}, Test F1 {:.4f}, Test ROC_AUC {:.4f}, Test AP {:.4f}'.format(neg_log_loss,\n",
    "                                                                                                                                                 accuracy, \n",
    "                                                                                                                                                 precision, \n",
    "                                                                                                                                                 recall,\n",
    "                                                                                                                                                 f1,\n",
    "                                                                                                                                                 roc_auc, \n",
    "                                                                                                                                                 ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(model, X, y):\n",
    "#     y_actual = pd.Series(y.copy(), name='Actual')\n",
    "#     y_pred = pd.Series(model.predict(X), name='Predicted')\n",
    "#     df_confusion = pd.crosstab(y_actual, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "#     print(df_confusion)\n",
    "    \n",
    "    conf_mat = np.array(confusion_matrix(y, model.predict(X)))\n",
    "    print('Confusion Matrix with test dataset into the best model: \\n\\t\\tApproved\\tRejected\\nApproved\\t{} \\t\\t{} \\nRejected\\t{} \\t\\t{} \\n'.format(conf_mat[0,0], conf_mat[0,1], conf_mat[1,0], conf_mat[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampling(X, y, random_state=614):\n",
    "    X_ros, y_ros = RandomOverSampler(random_state=random_state).fit_resample(X, y)\n",
    "    # X_sm, y_sm = SMOTE(random_state=random_state, n_jobs=-1).fit_resample(X, y)\n",
    "    return X_ros, y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(X, y, random_state=614):\n",
    "    X_rus, y_rus = RandomUnderSampler(random_state=random_state).fit_resample(X, y)\n",
    "    return X_rus, y_rus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_plot(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:,-1]\n",
    "    false_pos_rate, true_pos_rate, proba = roc_curve(y, y_pred)\n",
    "    plt.figure()\n",
    "    plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "    plt.plot(false_pos_rate, true_pos_rate, marker=\".\", label='AUC: {}'.format(roc_auc_score(y, y_pred)))\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_recall_curve_plot(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:,-1]\n",
    "    precision, recall, proba = precision_recall_curve(y, y_pred)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, marker=\".\", label='AP: {}'.format(average_precision_score(y, y_pred)))\n",
    "    plt.title(\"Precision-Recall Curve.\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "executionInfo": {
     "elapsed": 203767,
     "status": "ok",
     "timestamp": 1654021557447,
     "user": {
      "displayName": "Diego Ribeiro de Oliveira Galdino",
      "userId": "09301364934909737437"
     },
     "user_tz": 240
    },
    "id": "69vIdBBsVLmZ",
    "outputId": "51d48183-e4f6-4422-926b-2a1649fae36b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_analysis(X_train, X_test, y_train, y_test, models, metrics, sampling=None, curves=False):\n",
    "    # Prepare X_train and X_test with one-hot and dummy encoding\n",
    "    X_train_hot, X_test_hot = pd.get_dummies(X_train), pd.get_dummies(X_test)\n",
    "    X_train_dum, X_test_dum = pd.get_dummies(X_train, drop_first=True), pd.get_dummies(X_test, drop_first=True)\n",
    "    \n",
    "    # Iterate through all models\n",
    "    for model in models:\n",
    "        # Model estimator and encoding\n",
    "        estimator = model['estimator']\n",
    "        if len(model['params']) != 0:\n",
    "            estimator.set_params(**model['params'])\n",
    "        encoding = model['encoding']\n",
    "        # Perform cross-validation, feature importance, and model prediction according to encoding\n",
    "        if encoding == 'hot':\n",
    "            # Cross-validation with train dataset\n",
    "            best_estimator = model_train(X_train_hot, y_train, metrics, estimator, sampling, curves)\n",
    "\n",
    "            # Print scores for test dataset\n",
    "            model_pred(best_estimator, X_test_hot, y_test)\n",
    "            conf_matrix(best_estimator, X_test_hot, y_test)\n",
    "\n",
    "            # Print feature importance or shap values if available for the estimator\n",
    "            feature_importance(best_estimator)\n",
    "        elif encoding == 'dummy':\n",
    "            # Cross-validation with train dataset\n",
    "            best_estimator = model_train(X_train_dum, y_train, metrics, estimator, sampling, curves)\n",
    "\n",
    "            # Print scores for test dataset\n",
    "            model_pred(best_estimator, X_test_dum, y_test)\n",
    "            conf_matrix(best_estimator, X_test_dum, y_test)\n",
    "\n",
    "            # Print feature importance or shap values if available for the estimator\n",
    "            feature_importance(best_estimator)\n",
    "        else:\n",
    "            # Cross-validation with train dataset\n",
    "            best_estimator = model_train(X_train, y_train, metrics, estimator, sampling, curves)\n",
    "\n",
    "            # Print scores for test dataset\n",
    "            model_pred(best_estimator, X_test, y_test)\n",
    "            conf_matrix(best_estimator, X_test, y_test)\n",
    "\n",
    "            # Print feature importance or shap values if available for the estimator\n",
    "            feature_importance(best_estimator)\n",
    "\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit default estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_feature = 'rejected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features = ['month_name', \n",
    "                'day_name',\n",
    "                'pharmacy',\n",
    "                'bin_pcn_group', \n",
    "                'drug_brand', \n",
    "                'drug_name', \n",
    "                'diag_letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['neg_log_loss','accuracy','precision','recall','f1','roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaires with models. Keys to be included: name, estimator, encoding, and params. Empty params for default.\n",
    "class_models = [{'name':'LGBMClassifier', 'estimator':LGBMClassifier(random_state=random_state, n_jobs=-1, importance_type='gain'), 'encoding':None, \n",
    "               'params':{}\n",
    "              },\n",
    "              {'name':'LogisticRegression', 'estimator':LogisticRegression(random_state=random_state, n_jobs=-1), 'encoding':'dummy', \n",
    "               'params':{}\n",
    "              }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_feature_selection(data.sample(1000000, random_state=random_state), dep_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[ind_features].copy().reset_index(drop=True)\n",
    "X_test = X_test[ind_features].copy().reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(importance_type='gain', random_state=614)\n",
      "Train log_loss: -2.8983, Train accuracy: 0.9161, Train precision: 0.2000, Train recall: 0.0000, Train f1: 0.0001, Train roc_auc: 0.8965, Proc Time: 7.13\n",
      "Test NegLogLoss -2.8793, Test Accuracy 0.9166, Test Precision 0.0000, Test Recall 0.0000, Test F1 0.0000, Test ROC_AUC 0.8963, Test AP 0.3168\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183327 \t\t2 \n",
      "Rejected\t16671 \t\t0 \n",
      "\n",
      "Feature Importance: month_name: 1014.6384798288345, day_name: 400.03614938259125, pharmacy: 15056.776073217392, bin_pcn_group: 69894.48554372787, drug_brand: 53862.84447526932, drug_name: 610249.0320568085, diag_letter: 2674.774471640587\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -2.8989, Train accuracy: 0.9161, Train precision: 0.3865, Train recall: 0.0003, Train f1: 0.0007, Train roc_auc: 0.8887, Proc Time: 45.49\n",
      "Test NegLogLoss -2.8798, Test Accuracy 0.9166, Test Precision 0.2222, Test Recall 0.0001, Test F1 0.0002, Test ROC_AUC 0.8883, Test AP 0.3057\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183322 \t\t7 \n",
      "Rejected\t16669 \t\t2 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, class_models, metrics, sampling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(importance_type='gain', random_state=614)\n",
      "Train log_loss: -7.7990, Train accuracy: 0.7742, Train precision: 0.2696, Train recall: 0.9894, Train f1: 0.4237, Train roc_auc: 0.8938, Proc Time: 5.51\n",
      "Test NegLogLoss -7.7982, Test Accuracy 0.7742, Test Precision 0.2681, Test Recall 0.9880, Test F1 0.4218, Test ROC_AUC 0.8931, Test AP 0.3094\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t138374 \t\t44955 \n",
      "Rejected\t200 \t\t16471 \n",
      "\n",
      "Feature Importance: month_name: 1052.0977656841278, day_name: 220.11667943000793, pharmacy: 12393.505387187004, bin_pcn_group: 43982.16089183092, drug_brand: 37124.52215510607, drug_name: 354397.4075938463, diag_letter: 1121.7583729624748\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6904, Train accuracy: 0.7773, Train precision: 0.2639, Train recall: 0.9237, Train f1: 0.4105, Train roc_auc: 0.8866, Proc Time: 14.87\n",
      "Test NegLogLoss -7.7015, Test Accuracy 0.7770, Test Precision 0.2624, Test Recall 0.9248, Test F1 0.4088, Test ROC_AUC 0.8858, Test AP 0.2973\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139988 \t\t43341 \n",
      "Rejected\t1254 \t\t15417 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, class_models, metrics, sampling='under')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(importance_type='gain', random_state=614)\n",
      "Train log_loss: -7.6719, Train accuracy: 0.7779, Train precision: 0.2729, Train recall: 0.9898, Train f1: 0.4279, Train roc_auc: 0.8966, Proc Time: 15.24\n",
      "Test NegLogLoss -7.6464, Test Accuracy 0.7786, Test Precision 0.2722, Test Recall 0.9893, Test F1 0.4269, Test ROC_AUC 0.8961, Test AP 0.3152\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139231 \t\t44098 \n",
      "Rejected\t178 \t\t16493 \n",
      "\n",
      "Feature Importance: month_name: 3089.8508553504944, day_name: 651.6564726829529, pharmacy: 65386.47308254242, bin_pcn_group: 464145.2348036766, drug_brand: 383395.19847917557, drug_name: 3901507.930141926, diag_letter: 12724.14035320282\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6876, Train accuracy: 0.7774, Train precision: 0.2639, Train recall: 0.9236, Train f1: 0.4105, Train roc_auc: 0.8870, Proc Time: 93.84\n",
      "Test NegLogLoss -7.6842, Test Accuracy 0.7775, Test Precision 0.2624, Test Recall 0.9218, Test F1 0.4085, Test ROC_AUC 0.8866, Test AP 0.2990\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140138 \t\t43191 \n",
      "Rejected\t1304 \t\t15367 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, class_models, metrics, sampling='over')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(importance_type='gain', learning_rate=0.5, max_depth=6,\n",
      "               n_estimators=600, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.1975, Train accuracy: 0.7916, Train precision: 0.2735, Train recall: 0.8958, Train f1: 0.4191, Train roc_auc: 0.8827, Proc Time: 22.25\n",
      "Test NegLogLoss -7.1619, Test Accuracy 0.7926, Test Precision 0.2732, Test Recall 0.8959, Test F1 0.4187, Test ROC_AUC 0.8826, Test AP 0.2848\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t143594 \t\t39735 \n",
      "Rejected\t1736 \t\t14935 \n",
      "\n",
      "Feature Importance: month_name: 9145.591007133946, day_name: 3562.293183497637, pharmacy: 27996.34331912233, bin_pcn_group: 26280.366894334555, drug_brand: 9375.606495789947, drug_name: 99816.40008369938, diag_letter: 5380.387713730801\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(importance_type='gain', max_depth=6, n_estimators=600,\n",
      "               num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.4710, Train accuracy: 0.7837, Train precision: 0.2745, Train recall: 0.9601, Train f1: 0.4269, Train roc_auc: 0.8864, Proc Time: 20.69\n",
      "Test NegLogLoss -7.4514, Test Accuracy 0.7843, Test Precision 0.2732, Test Recall 0.9562, Test F1 0.4249, Test ROC_AUC 0.8857, Test AP 0.2896\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140913 \t\t42416 \n",
      "Rejected\t731 \t\t15940 \n",
      "\n",
      "Feature Importance: month_name: 17518.95439743044, day_name: 4662.671922937036, pharmacy: 63000.7001378038, bin_pcn_group: 76970.38902484108, drug_brand: 38105.03602066463, drug_name: 377235.0955413375, diag_letter: 10427.691695915768\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(importance_type='gain', learning_rate=0.5, max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.1846, Train accuracy: 0.7920, Train precision: 0.2736, Train recall: 0.8939, Train f1: 0.4190, Train roc_auc: 0.8828, Proc Time: 34.25\n",
      "Test NegLogLoss -7.1604, Test Accuracy 0.7927, Test Precision 0.2726, Test Recall 0.8915, Test F1 0.4176, Test ROC_AUC 0.8827, Test AP 0.2855\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t143675 \t\t39654 \n",
      "Rejected\t1808 \t\t14863 \n",
      "\n",
      "Feature Importance: month_name: 9566.884613283735, day_name: 3812.4505674450957, pharmacy: 28964.0782156981, bin_pcn_group: 26738.06774871319, drug_brand: 9415.291394834203, drug_name: 100142.71926990605, diag_letter: 5598.409121319884\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(importance_type='gain', max_depth=6, n_estimators=900,\n",
      "               num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.3949, Train accuracy: 0.7859, Train precision: 0.2748, Train recall: 0.9470, Train f1: 0.4260, Train roc_auc: 0.8853, Proc Time: 29.09\n",
      "Test NegLogLoss -7.3737, Test Accuracy 0.7865, Test Precision 0.2736, Test Recall 0.9431, Test F1 0.4241, Test ROC_AUC 0.8845, Test AP 0.2866\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t141580 \t\t41749 \n",
      "Rejected\t948 \t\t15723 \n",
      "\n",
      "Feature Importance: month_name: 23620.571035888308, day_name: 6780.392938741366, pharmacy: 78524.22873620712, bin_pcn_group: 85584.14462219166, drug_brand: 38171.02235537595, drug_name: 383349.67423933465, diag_letter: 13690.753740262473\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', learning_rate=0.5,\n",
      "               max_depth=6, n_estimators=600, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.3358, Train accuracy: 0.7876, Train precision: 0.2747, Train recall: 0.9332, Train f1: 0.4244, Train roc_auc: 0.8849, Proc Time: 86.36\n",
      "Test NegLogLoss -7.3338, Test Accuracy 0.7877, Test Precision 0.2731, Test Recall 0.9310, Test F1 0.4223, Test ROC_AUC 0.8841, Test AP 0.2869\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t142014 \t\t41315 \n",
      "Rejected\t1151 \t\t15520 \n",
      "\n",
      "Feature Importance: month_name: 16241.71940420469, day_name: 4553.782216196065, pharmacy: 57542.62511675106, bin_pcn_group: 61422.91894899495, drug_brand: 14122.79623334885, drug_name: 139598.3125469368, diag_letter: 9869.818687971681\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=600, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.6863, Train accuracy: 0.7775, Train precision: 0.2724, Train recall: 0.9884, Train f1: 0.4271, Train roc_auc: 0.8917, Proc Time: 75.88\n",
      "Test NegLogLoss -7.6635, Test Accuracy 0.7781, Test Precision 0.2715, Test Recall 0.9870, Test F1 0.4258, Test ROC_AUC 0.8910, Test AP 0.3040\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139171 \t\t44158 \n",
      "Rejected\t217 \t\t16454 \n",
      "\n",
      "Feature Importance: month_name: 8371.013180866838, day_name: 2000.5798041298985, pharmacy: 64167.39419762418, bin_pcn_group: 171411.56019348523, drug_brand: 98876.5070684327, drug_name: 899454.6629593112, diag_letter: 8985.615344840102\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', learning_rate=0.5,\n",
      "               max_depth=6, n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.3119, Train accuracy: 0.7883, Train precision: 0.2745, Train recall: 0.9267, Train f1: 0.4235, Train roc_auc: 0.8845, Proc Time: 166.98\n",
      "Test NegLogLoss -7.3068, Test Accuracy 0.7884, Test Precision 0.2728, Test Recall 0.9232, Test F1 0.4211, Test ROC_AUC 0.8838, Test AP 0.2862\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t142300 \t\t41029 \n",
      "Rejected\t1281 \t\t15390 \n",
      "\n",
      "Feature Importance: month_name: 21822.98550917738, day_name: 6423.664529520203, pharmacy: 72878.29871722916, bin_pcn_group: 71108.06550858129, drug_brand: 14392.291767760715, drug_name: 146834.767686571, diag_letter: 12823.19466901198\n",
      "\n",
      "\n",
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.6471, Train accuracy: 0.7786, Train precision: 0.2730, Train recall: 0.9849, Train f1: 0.4274, Train roc_auc: 0.8907, Proc Time: 142.82\n",
      "Test NegLogLoss -7.6227, Test Accuracy 0.7793, Test Precision 0.2722, Test Recall 0.9840, Test F1 0.4264, Test ROC_AUC 0.8898, Test AP 0.3006\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139456 \t\t43873 \n",
      "Rejected\t266 \t\t16405 \n",
      "\n",
      "Feature Importance: month_name: 14322.705016475637, day_name: 3681.534614039585, pharmacy: 89538.4095121636, bin_pcn_group: 195074.48230042693, drug_brand: 99801.60242862481, drug_name: 920342.7632730878, diag_letter: 13826.668092693202\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(C=0.01, n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.8690, Train accuracy: 0.7722, Train precision: 0.2586, Train recall: 0.9189, Train f1: 0.4037, Train roc_auc: 0.8817, Proc Time: 10.59\n",
      "Test NegLogLoss -7.8626, Test Accuracy 0.7724, Test Precision 0.2575, Test Recall 0.9187, Test F1 0.4022, Test ROC_AUC 0.8812, Test AP 0.2965\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139157 \t\t44172 \n",
      "Rejected\t1356 \t\t15315 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(C=0.1, n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6725, Train accuracy: 0.7779, Train precision: 0.2638, Train recall: 0.9202, Train f1: 0.4101, Train roc_auc: 0.8860, Proc Time: 13.38\n",
      "Test NegLogLoss -7.6662, Test Accuracy 0.7780, Test Precision 0.2626, Test Recall 0.9196, Test F1 0.4085, Test ROC_AUC 0.8851, Test AP 0.2971\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140279 \t\t43050 \n",
      "Rejected\t1341 \t\t15330 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6904, Train accuracy: 0.7773, Train precision: 0.2639, Train recall: 0.9237, Train f1: 0.4105, Train roc_auc: 0.8866, Proc Time: 14.31\n",
      "Test NegLogLoss -7.7015, Test Accuracy 0.7770, Test Precision 0.2624, Test Recall 0.9248, Test F1 0.4088, Test ROC_AUC 0.8858, Test AP 0.2973\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139988 \t\t43341 \n",
      "Rejected\t1254 \t\t15417 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(C=0.01, n_jobs=1, random_state=614, solver='sag')\n",
      "Train log_loss: -7.8690, Train accuracy: 0.7722, Train precision: 0.2586, Train recall: 0.9189, Train f1: 0.4037, Train roc_auc: 0.8817, Proc Time: 20.65\n",
      "Test NegLogLoss -7.8626, Test Accuracy 0.7724, Test Precision 0.2575, Test Recall 0.9187, Test F1 0.4022, Test ROC_AUC 0.8812, Test AP 0.2965\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139157 \t\t44172 \n",
      "Rejected\t1356 \t\t15315 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LogisticRegression(C=0.1, n_jobs=1, random_state=614, solver='sag')\n",
      "Train log_loss: -7.6726, Train accuracy: 0.7779, Train precision: 0.2638, Train recall: 0.9202, Train f1: 0.4101, Train roc_auc: 0.8860, Proc Time: 24.30\n",
      "Test NegLogLoss -7.6667, Test Accuracy 0.7780, Test Precision 0.2626, Test Recall 0.9196, Test F1 0.4085, Test ROC_AUC 0.8851, Test AP 0.2971\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140276 \t\t43053 \n",
      "Rejected\t1341 \t\t15330 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614, solver='sag')\n",
      "Train log_loss: -7.6904, Train accuracy: 0.7773, Train precision: 0.2638, Train recall: 0.9236, Train f1: 0.4104, Train roc_auc: 0.8866, Proc Time: 38.02\n",
      "Test NegLogLoss -7.6947, Test Accuracy 0.7772, Test Precision 0.2625, Test Recall 0.9241, Test F1 0.4088, Test ROC_AUC 0.8858, Test AP 0.2972\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140039 \t\t43290 \n",
      "Rejected\t1266 \t\t15405 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(C=0.01, n_jobs=1, random_state=614, solver='saga')\n",
      "Train log_loss: -7.8689, Train accuracy: 0.7722, Train precision: 0.2586, Train recall: 0.9189, Train f1: 0.4037, Train roc_auc: 0.8817, Proc Time: 27.24\n",
      "Test NegLogLoss -7.8628, Test Accuracy 0.7724, Test Precision 0.2574, Test Recall 0.9187, Test F1 0.4022, Test ROC_AUC 0.8812, Test AP 0.2965\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139156 \t\t44173 \n",
      "Rejected\t1356 \t\t15315 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(C=0.1, n_jobs=1, random_state=614, solver='saga')\n",
      "Train log_loss: -7.6724, Train accuracy: 0.7779, Train precision: 0.2638, Train recall: 0.9202, Train f1: 0.4101, Train roc_auc: 0.8860, Proc Time: 27.50\n",
      "Test NegLogLoss -7.6666, Test Accuracy 0.7780, Test Precision 0.2626, Test Recall 0.9196, Test F1 0.4085, Test ROC_AUC 0.8851, Test AP 0.2971\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140277 \t\t43052 \n",
      "Rejected\t1341 \t\t15330 \n",
      "\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614, solver='saga')\n",
      "Train log_loss: -7.6901, Train accuracy: 0.7774, Train precision: 0.2638, Train recall: 0.9236, Train f1: 0.4104, Train roc_auc: 0.8866, Proc Time: 28.19\n",
      "Test NegLogLoss -7.6945, Test Accuracy 0.7772, Test Precision 0.2625, Test Recall 0.9241, Test F1 0.4088, Test ROC_AUC 0.8858, Test AP 0.2972\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140039 \t\t43290 \n",
      "Rejected\t1265 \t\t15406 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of dictionaires with models. Keys to be included: name, estimator, encoding, and params.\n",
    "all_params = list(product(*[['gbdt', 'dart'], [600, 900], [0.5, 0.1], [248], [6]]))\n",
    "for params in all_params:\n",
    "    class_models = [{'name':'LGBMClassifier', 'estimator':LGBMClassifier(random_state=random_state, n_jobs=-1, importance_type='gain'), 'encoding':None, \n",
    "                   'params':{'boosting_type':params[0],\n",
    "                             'n_estimators':params[1],\n",
    "                             'learning_rate':params[2],\n",
    "                             'num_leaves':params[3],\n",
    "                             'max_depth':params[4]\n",
    "                            }\n",
    "                      }]\n",
    "    model_analysis(X_train, X_test, y_train, y_test, class_models, metrics, sampling='under')\n",
    "\n",
    "all_params = list(product(*[['lbfgs', 'sag', 'saga'], [0.01, 0.1, 1.0]]))\n",
    "for params in all_params:\n",
    "    class_models = [{'name':'LogisticRegression', 'estimator':LogisticRegression(random_state=random_state, n_jobs=-1), 'encoding':'dummy', \n",
    "                       'params':{'solver':params[0], \n",
    "                                 'C':params[1]}\n",
    "                      }]\n",
    "\n",
    "    model_analysis(X_train, X_test, y_train, y_test, class_models, metrics, sampling='under')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit best estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaires with models. Keys to be included: name, estimator, encoding, and params.\n",
    "best_estimators = [{'name':'LGBMClassifier', 'estimator':LGBMClassifier(random_state=random_state, n_jobs=-1, importance_type='gain'), 'encoding':None, \n",
    "                   'params':{'boosting_type':'dart',\n",
    "                             'n_estimators':900,\n",
    "                             'learning_rate':0.1,\n",
    "                             'num_leaves':248,\n",
    "                             'max_depth':6\n",
    "                            }\n",
    "                  },\n",
    "                  {'name':'LogisticRegression', 'estimator':LogisticRegression(random_state=random_state, n_jobs=-1), 'encoding':'dummy', \n",
    "                   'params':{}\n",
    "                  }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 million sample dataset and keeping all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_feature_selection(data.sample(1000000, random_state=random_state), dep_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[ind_features].copy().reset_index(drop=True)\n",
    "X_test = X_test[ind_features].copy().reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -2.9018, Train accuracy: 0.9160, Train precision: 0.2875, Train recall: 0.0008, Train f1: 0.0017, Train roc_auc: 0.8952, Proc Time: 573.05\n",
      "Test NegLogLoss -2.8835, Test Accuracy 0.9165, Test Precision 0.2045, Test Recall 0.0005, Test F1 0.0011, Test ROC_AUC 0.8950, Test AP 0.3131\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183294 \t\t35 \n",
      "Rejected\t16662 \t\t9 \n",
      "\n",
      "Feature Importance: month_name: 21101.392351688846, day_name: 5845.179598968476, pharmacy: 125054.6878692942, bin_pcn_group: 286234.68174724374, drug_brand: 135243.38745558498, drug_name: 1530427.1331846751, diag_letter: 22727.01460572006\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -2.8989, Train accuracy: 0.9161, Train precision: 0.3865, Train recall: 0.0003, Train f1: 0.0007, Train roc_auc: 0.8887, Proc Time: 41.88\n",
      "Test NegLogLoss -2.8798, Test Accuracy 0.9166, Test Precision 0.2222, Test Recall 0.0001, Test F1 0.0002, Test ROC_AUC 0.8883, Test AP 0.3057\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183322 \t\t7 \n",
      "Rejected\t16669 \t\t2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling=None, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.6471, Train accuracy: 0.7786, Train precision: 0.2730, Train recall: 0.9849, Train f1: 0.4274, Train roc_auc: 0.8907, Proc Time: 140.64\n",
      "Test NegLogLoss -7.6227, Test Accuracy 0.7793, Test Precision 0.2722, Test Recall 0.9840, Test F1 0.4264, Test ROC_AUC 0.8898, Test AP 0.3006\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139456 \t\t43873 \n",
      "Rejected\t266 \t\t16405 \n",
      "\n",
      "Feature Importance: month_name: 14322.705016475637, day_name: 3681.534614039585, pharmacy: 89538.4095121636, bin_pcn_group: 195074.48230042693, drug_brand: 99801.60242862481, drug_name: 920342.7632730878, diag_letter: 13826.668092693202\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6904, Train accuracy: 0.7773, Train precision: 0.2639, Train recall: 0.9237, Train f1: 0.4105, Train roc_auc: 0.8866, Proc Time: 13.61\n",
      "Test NegLogLoss -7.7015, Test Accuracy 0.7770, Test Precision 0.2624, Test Recall 0.9248, Test F1 0.4088, Test ROC_AUC 0.8858, Test AP 0.2973\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139988 \t\t43341 \n",
      "Rejected\t1254 \t\t15417 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling='under', curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.4809, Train accuracy: 0.7834, Train precision: 0.2762, Train recall: 0.9753, Train f1: 0.4304, Train roc_auc: 0.8954, Proc Time: 1084.51\n",
      "Test NegLogLoss -7.4728, Test Accuracy 0.7836, Test Precision 0.2751, Test Recall 0.9761, Test F1 0.4293, Test ROC_AUC 0.8951, Test AP 0.3139\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140456 \t\t42873 \n",
      "Rejected\t398 \t\t16273 \n",
      "\n",
      "Feature Importance: month_name: 70609.42877195752, day_name: 19375.43375968933, pharmacy: 495098.029482109, bin_pcn_group: 1834416.882346809, drug_brand: 930252.9187456628, drug_name: 9884308.670326069, diag_letter: 91926.23599145561\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6876, Train accuracy: 0.7774, Train precision: 0.2639, Train recall: 0.9236, Train f1: 0.4105, Train roc_auc: 0.8870, Proc Time: 91.78\n",
      "Test NegLogLoss -7.6842, Test Accuracy 0.7775, Test Precision 0.2624, Test Recall 0.9218, Test F1 0.4085, Test ROC_AUC 0.8866, Test AP 0.2990\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140138 \t\t43191 \n",
      "Rejected\t1304 \t\t15367 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling='over', curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 million sample dataset and keeping only plan-, drug-, and diagnosis-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features = ['bin_pcn_group', \n",
    "                'drug_brand', \n",
    "                'drug_name', \n",
    "                'diag_letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split_feature_selection(data.sample(1000000,random_state=random_state), dep_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[ind_features].copy().reset_index(drop=True)\n",
    "X_test = X_test[ind_features].copy().reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -2.9025, Train accuracy: 0.9160, Train precision: 0.3032, Train recall: 0.0010, Train f1: 0.0021, Train roc_auc: 0.8972, Proc Time: 559.81\n",
      "Test NegLogLoss -2.8811, Test Accuracy 0.9166, Test Precision 0.3333, Test Recall 0.0007, Test F1 0.0014, Test ROC_AUC 0.8963, Test AP 0.3149\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183305 \t\t24 \n",
      "Rejected\t16659 \t\t12 \n",
      "\n",
      "Feature Importance: bin_pcn_group: 251528.8164871902, drug_brand: 134858.32882594474, drug_name: 1502017.317035113, diag_letter: 24329.940329660894\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -2.8991, Train accuracy: 0.9161, Train precision: 0.2886, Train recall: 0.0004, Train f1: 0.0008, Train roc_auc: 0.8888, Proc Time: 27.15\n",
      "Test NegLogLoss -2.8790, Test Accuracy 0.9166, Test Precision 0.0000, Test Recall 0.0000, Test F1 0.0000, Test ROC_AUC 0.8883, Test AP 0.3055\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t183329 \t\t0 \n",
      "Rejected\t16671 \t\t0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling=None, curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.6474, Train accuracy: 0.7786, Train precision: 0.2740, Train recall: 0.9932, Train f1: 0.4295, Train roc_auc: 0.8937, Proc Time: 129.20\n",
      "Test NegLogLoss -7.6303, Test Accuracy 0.7791, Test Precision 0.2731, Test Recall 0.9929, Test F1 0.4283, Test ROC_AUC 0.8928, Test AP 0.3058\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139264 \t\t44065 \n",
      "Rejected\t118 \t\t16553 \n",
      "\n",
      "Feature Importance: bin_pcn_group: 168490.51611702738, drug_brand: 99559.1972856368, drug_name: 899558.080871395, diag_letter: 15202.892036322592\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6845, Train accuracy: 0.7775, Train precision: 0.2639, Train recall: 0.9231, Train f1: 0.4105, Train roc_auc: 0.8868, Proc Time: 9.89\n",
      "Test NegLogLoss -7.6935, Test Accuracy 0.7773, Test Precision 0.2624, Test Recall 0.9232, Test F1 0.4086, Test ROC_AUC 0.8859, Test AP 0.2975\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140060 \t\t43269 \n",
      "Rejected\t1280 \t\t15391 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling='under', curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Model: LGBMClassifier(boosting_type='dart', importance_type='gain', max_depth=6,\n",
      "               n_estimators=900, num_leaves=248, random_state=614)\n",
      "Train log_loss: -7.6304, Train accuracy: 0.7791, Train precision: 0.2743, Train recall: 0.9922, Train f1: 0.4298, Train roc_auc: 0.8970, Proc Time: 1134.07\n",
      "Test NegLogLoss -7.6167, Test Accuracy 0.7795, Test Precision 0.2734, Test Recall 0.9929, Test F1 0.4288, Test ROC_AUC 0.8963, Test AP 0.3152\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t139344 \t\t43985 \n",
      "Rejected\t119 \t\t16552 \n",
      "\n",
      "Feature Importance: bin_pcn_group: 1748485.522760203, drug_brand: 926456.7632331903, drug_name: 9761797.66451547, diag_letter: 109391.95908555994\n",
      "\n",
      "\n",
      "-> Model: LogisticRegression(n_jobs=1, random_state=614)\n",
      "Train log_loss: -7.6853, Train accuracy: 0.7775, Train precision: 0.2639, Train recall: 0.9228, Train f1: 0.4104, Train roc_auc: 0.8870, Proc Time: 59.26\n",
      "Test NegLogLoss -7.6742, Test Accuracy 0.7778, Test Precision 0.2625, Test Recall 0.9206, Test F1 0.4085, Test ROC_AUC 0.8865, Test AP 0.2988\n",
      "Confusion Matrix with test dataset into the best model: \n",
      "\t\tApproved\tRejected\n",
      "Approved\t140216 \t\t43113 \n",
      "Rejected\t1324 \t\t15347 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_analysis(X_train, X_test, y_train, y_test, best_estimators, metrics, sampling='over', curves=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1. Erdos Bootcamp May 2022 - CoverMyMeds Project.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
